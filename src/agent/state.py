"""
Agent State Definition
This is the "memory" of our AI agent that persists across all nodes
"""

from typing import TypedDict, List, Optional, Literal
from datetime import datetime


class CodeAgentState(TypedDict):
    """
    Complete state for the code generation agent
    
    This state flows through all nodes in the LangGraph workflow.
    Each node can read from and write to this state.
    """
    
    # ===== INPUT DATA =====
    problem_description: str  # The programming problem from .txt file
    target_language: str  # Programming language (python, javascript, java, etc.)
    input_file_path: str  # Path to the input .txt file
    
    # ===== CODE GENERATION =====
    generated_code: str  # The code generated by LLM
    code_explanation: str  # LLM's explanation of the code
    
    # ===== EXECUTION RESULTS =====
    execution_output: str  # Output from running the code
    execution_error: str  # Error messages if execution failed
    execution_success: bool  # Did the code run without errors?
    execution_time_ms: float  # How long did execution take
    
    # ===== VALIDATION RESULTS =====
    validation_passed: bool  # Did all validations pass?
    validation_errors: List[str]  # List of validation errors
    validation_details: dict  # Detailed validation results
    
    # Validation Sub-Categories
    functional_valid: bool  # Does the code solve the problem?
    security_valid: bool  # Is the code safe to run?
    quality_valid: bool  # Does it meet code quality standards?
    performance_valid: bool  # Is it efficient enough?
    
    # ===== FEEDBACK & ITERATION =====
    iteration_count: int  # Current iteration number
    max_iterations: int  # Maximum allowed iterations
    feedback_history: List[str]  # All feedback messages across iterations
    current_feedback: str  # Feedback for current iteration
    
    # ===== LLM TRACKING =====
    llm_model_used: str  # Which model generated the code
    total_tokens_used: int  # Total tokens consumed
    llm_cost_usd: float  # Estimated cost in USD
    llm_calls_made: int  # Number of LLM API calls
    
    # ===== METADATA =====
    session_id: str  # Unique ID for this generation session
    start_time: str  # When generation started (ISO format)
    end_time: Optional[str]  # When generation completed
    status: Literal["pending", "generating", "validating", "completed", "failed"]
    
    # ===== OUTPUT =====
    output_file_path: Optional[str]  # Path to generated .docx file
    final_success: bool  # Overall success status
    error_message: Optional[str]  # Final error message if failed


def create_initial_state(
    problem_description: str,
    target_language: str,
    input_file_path: str,
    max_iterations: int = 5
) -> CodeAgentState:
    """
    Create initial state for a new code generation session
    
    Args:
        problem_description: The programming problem to solve
        target_language: Programming language to use
        input_file_path: Path to input .txt file
        max_iterations: Maximum retry attempts
        
    Returns:
        Initial CodeAgentState with defaults
    """
    import uuid
    
    return CodeAgentState(
        # Input
        problem_description=problem_description,
        target_language=target_language.lower(),
        input_file_path=input_file_path,
        
        # Code Generation
        generated_code="",
        code_explanation="",
        
        # Execution
        execution_output="",
        execution_error="",
        execution_success=False,
        execution_time_ms=0.0,
        
        # Validation
        validation_passed=False,
        validation_errors=[],
        validation_details={},
        functional_valid=False,
        security_valid=False,
        quality_valid=False,
        performance_valid=False,
        
        # Feedback & Iteration
        iteration_count=0,
        max_iterations=max_iterations,
        feedback_history=[],
        current_feedback="",
        
        # LLM Tracking
        llm_model_used="",
        total_tokens_used=0,
        llm_cost_usd=0.0,
        llm_calls_made=0,
        
        # Metadata
        session_id=str(uuid.uuid4()),
        start_time=datetime.utcnow().isoformat(),
        end_time=None,
        status="pending",
        
        # Output
        output_file_path=None,
        final_success=False,
        error_message=None,
    )
